% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cross_validation.R
\name{cf_cv}
\alias{cf_cv}
\title{Cross-Validation with Counterfactual Performance Metrics}
\usage{
cf_cv(
  formula,
  data,
  treatment,
  treatment_level = 0,
  nuisance_covariates = NULL,
  metric = c("mse", "auc", "both"),
  estimator = c("dr", "cl", "ipw", "naive"),
  K = 5,
  repeats = 1,
  stratify = TRUE,
  seed = NULL,
  ...
)
}
\arguments{
\item{formula}{A formula specifying the prediction model (e.g., \code{Y ~ X1 + X2}).}

\item{data}{A data frame containing the variables in the formula plus
\code{treatment} and any additional covariates for nuisance models.}

\item{treatment}{Character string naming the treatment variable in \code{data}.}

\item{treatment_level}{The counterfactual treatment level (default: 0).}

\item{nuisance_covariates}{Character vector of covariate names for nuisance
models. If NULL, uses all predictors from the formula.}

\item{metric}{Character string specifying the performance metric:
\code{"mse"} (default), \code{"auc"}, or \code{"both"}.}

\item{estimator}{Character string specifying the estimator:
\code{"dr"} (default), \code{"cl"}, \code{"ipw"}, or \code{"naive"}.}

\item{K}{Number of folds (default: 5).}

\item{repeats}{Number of times to repeat K-fold CV (default: 1).}

\item{stratify}{Logical indicating whether to stratify folds by outcome
(default: TRUE for binary outcomes).}

\item{seed}{Random seed for reproducibility (default: NULL).}

\item{...}{Additional arguments passed to internal functions.}
}
\value{
An object of class \code{cf_cv} containing:
\item{results}{Data frame with fold-level performance estimates}
\item{summary}{Summary statistics across folds}
\item{metric}{Performance metric used}
\item{estimator}{Estimator used}
\item{K}{Number of folds}
\item{repeats}{Number of repeats}
\item{call}{The matched call}
}
\description{
Performs K-fold cross-validation to estimate out-of-sample counterfactual
model performance. This function trains and evaluates prediction models
while properly accounting for treatment effects.
}
\details{
Cross-validation for counterfactual prediction models requires special care:
\enumerate{
\item \strong{Nuisance model estimation}: Propensity and outcome models are re-fit
in each training fold to avoid overfitting.
\item \strong{Sample splitting}: The prediction model is trained on the training
fold and evaluated on the test fold using counterfactual estimators.
\item \strong{Stratification}: For binary outcomes, stratified sampling ensures
each fold has similar outcome prevalence.
}
}
\examples{
# Generate example data
set.seed(123)
n <- 300
data <- data.frame(
  x1 = rnorm(n),
  x2 = rnorm(n)
)
data$a <- rbinom(n, 1, plogis(-0.5 + 0.5 * data$x1))
data$y <- rbinom(n, 1, plogis(-1 + data$x1 + 0.5 * data$x2 - 0.3 * data$a))

# 5-fold cross-validation
cv_result <- cf_cv(
  formula = y ~ x1 + x2,
  data = data,
  treatment = "a",
  treatment_level = 0,
  metric = "mse",
  K = 5
)
print(cv_result)
}
\references{
Boyer, C. B., Dahabreh, I. J., & Steingrimsson, J. A. (2025).
"Estimating and evaluating counterfactual prediction models."
\emph{Statistics in Medicine}, 44(23-24), e70287. \doi{10.1002/sim.70287}
}
\seealso{
\code{\link[=cf_mse]{cf_mse()}}, \code{\link[=cf_auc]{cf_auc()}}, \code{\link[=cf_compare]{cf_compare()}}
}
